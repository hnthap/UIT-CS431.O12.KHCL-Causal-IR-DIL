{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal-IR-DIR áp dụng trên McMaster dataset bằng $\\text{DIR}_{\\text{sf}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\C15TQK\\anaconda3\\envs\\uit-cs431\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "import torch.optim as optim\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up về việc có dùng Google Colab hay không"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nếu đang chạy trên Google Colab thì path đến file ZIP của dataset sẽ được cập nhật theo shortcut trên Google Drive. (Xem thêm trong file `README.md`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook is not running on Google Colab\n"
     ]
    }
   ],
   "source": [
    "is_gcolab: bool = False\n",
    "try:\n",
    "    if str(get_ipython()) == 'google.colab':\n",
    "        is_gcolab = True\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "if is_gcolab:\n",
    "    print('This notebook is running on Google Colab')\n",
    "else:\n",
    "    print('This notebook is not running on Google Colab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Because this is not running with Google Colab, data will not be mounted from Google Drive\n"
     ]
    }
   ],
   "source": [
    "if is_gcolab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/gdrive')\n",
    "    print('Mounted from Google Drive')\n",
    "else:\n",
    "    print('Because this is not running with Google Colab, '+\n",
    "          'data will not be mounted from Google Drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dữ liệu\n",
    "\n",
    "McMaster dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./McM.zip\n"
     ]
    }
   ],
   "source": [
    "# Set the path to ZIP file\n",
    "\n",
    "data_zip_filepath = None\n",
    "if is_gcolab:\n",
    "    data_zip_filepath = '/gdrive/MyDrive/McM.zip'\n",
    "else:\n",
    "    data_zip_filepath = './McM.zip'\n",
    "\n",
    "assert data_zip_filepath is not None\n",
    "assert os.path.exists(data_zip_filepath)\n",
    "\n",
    "print(data_zip_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./McM\n"
     ]
    }
   ],
   "source": [
    "# Extract all from ZIP file\n",
    "\n",
    "data_dirpath = './McM'\n",
    "\n",
    "with ZipFile(data_zip_filepath, 'r') as zip_ref:\n",
    "    zip_ref.extractall(data_dirpath, pwd='McM_CDM'.encode('utf-8'))\n",
    "\n",
    "assert data_dirpath is not None\n",
    "assert os.path.exists(data_dirpath)\n",
    "\n",
    "print(data_dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiền xử lý"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cắt ảnh ra theo patch 256x256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./McM/McM done!\n"
     ]
    }
   ],
   "source": [
    "# %run -i generate_cropped_DF2K.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "folder = './McM/McM'\n",
    "dest_folder = './McM-cropped'\n",
    "\n",
    "if not os.path.exists(dest_folder):\n",
    "    os.makedirs(dest_folder)\n",
    "\n",
    "patchsize = 256\n",
    "stride = 256\n",
    "\n",
    "count = 1\n",
    "\n",
    "for img_n in sorted(os.listdir(folder)):\n",
    "    img = cv2.imread(os.path.join(folder, img_n))\n",
    "    h, w, _ = img.shape\n",
    "    h_number = h // patchsize\n",
    "    w_number = w // patchsize\n",
    "    for i in range(h_number):\n",
    "        for j in range(w_number):\n",
    "            start_ij_l = j * stride\n",
    "            start_ij_u = i * stride\n",
    "            end_ij_l = start_ij_l + stride\n",
    "            end_ij_u = start_ij_u + stride\n",
    "            img_crop = img[start_ij_u:end_ij_u, start_ij_l:end_ij_l]\n",
    "            cv2.imwrite(os.path.join(dest_folder, '{:0>6d}.png'.format(count)), img_crop)\n",
    "            count += 1\n",
    "print(\"{} done!\".format(folder))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Không biết đang làm gì"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### srdata_noise.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "\n",
    "class DataCrop(data.Dataset):\n",
    "    def __init__(self, choose, hr_folder, patch_size=64):\n",
    "        self.patch_size = patch_size\n",
    "        self.dir_hr = hr_folder\n",
    "        self.images_hr = sorted(glob.glob(os.path.join(self.dir_hr, '*.png')))\n",
    "        self.choose = (choose + 1) * 5  # 5, 10, 15, 20\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.images_hr[idx].split('/')[-1]\n",
    "\n",
    "        hr = cv2.imread(os.path.join(self.dir_hr, filename))  # BGR, n_channels=3        \n",
    "        hr = cv2.cvtColor(hr, cv2.COLOR_BGR2RGB)  # RGB, n_channels=3\n",
    "\n",
    "        croph = np.random.randint(0, 256 - self.patch_size)\n",
    "        cropw = np.random.randint(0, 256 - self.patch_size)\n",
    "        hr = hr[croph: croph+self.patch_size, cropw: cropw+self.patch_size, :]\n",
    "\n",
    "        mode = np.random.randint(0, 8)\n",
    "        hr = augment_img(hr, mode=mode)\n",
    "\n",
    "        hr = hr.astype(np.float32) / 255.\n",
    "        lr = hr.copy()\n",
    "\n",
    "        noise = np.random.randn(*hr.shape) * self.choose / 255.\n",
    "\n",
    "        lr += noise\n",
    "\n",
    "        lr = np.clip(lr, 0, 1).astype(np.float32)\n",
    "\n",
    "        lr = torch.from_numpy(np.ascontiguousarray(lr.transpose(2, 0, 1)))\n",
    "        hr = torch.from_numpy(np.ascontiguousarray(hr.transpose(2, 0, 1)))\n",
    "\n",
    "        return lr, hr\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_hr)\n",
    "\n",
    "\n",
    "class DataTest(data.Dataset):\n",
    "    def __init__(self, hr_folder='default', level=50):\n",
    "\n",
    "        self.dir_hr = 'Set5/HR' if hr_folder == 'default' else hr_folder\n",
    "        self.name_hr = sorted(os.listdir(self.dir_hr))\n",
    "        self.level = level\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name = self.name_hr[idx]\n",
    "        hr = cv2.cvtColor(cv2.imread(os.path.join(self.dir_hr, name)), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        hr = hr.astype(np.float32) / 255.\n",
    "        lr = hr.copy()\n",
    "\n",
    "        noise = np.random.randn(*hr.shape) * self.level / 255.\n",
    "\n",
    "        lr += noise\n",
    "\n",
    "        lr = np.clip(lr, 0, 1).astype(np.float32)\n",
    "\n",
    "        lr = torch.from_numpy(np.ascontiguousarray(lr.transpose(2, 0, 1)))\n",
    "        hr = torch.from_numpy(np.ascontiguousarray(hr.transpose(2, 0, 1)))\n",
    "\n",
    "        return lr, hr, name\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.name_hr)\n",
    "\n",
    "\n",
    "def augment_img(img, mode=0):\n",
    "    '''Kai Zhang (github: https://github.com/cszn)\n",
    "    '''\n",
    "    if mode == 0:\n",
    "        return img\n",
    "    elif mode == 1:\n",
    "        return np.flipud(np.rot90(img))\n",
    "    elif mode == 2:\n",
    "        return np.flipud(img)\n",
    "    elif mode == 3:\n",
    "        return np.rot90(img, k=3)\n",
    "    elif mode == 4:\n",
    "        return np.flipud(np.rot90(img, k=2))\n",
    "    elif mode == 5:\n",
    "        return np.rot90(img)\n",
    "    elif mode == 6:\n",
    "        return np.rot90(img, k=2)\n",
    "    elif mode == 7:\n",
    "        return np.flipud(np.rot90(img, k=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils_logger.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "\n",
    "'''\n",
    "# --------------------------------------------\n",
    "# Kai Zhang (github: https://github.com/cszn)\n",
    "# 03/Mar/2019\n",
    "# --------------------------------------------\n",
    "# https://github.com/xinntao/BasicSR\n",
    "# --------------------------------------------\n",
    "'''\n",
    "\n",
    "\n",
    "def log(*args, **kwargs):\n",
    "    print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S:\"), *args, **kwargs)\n",
    "\n",
    "\n",
    "'''\n",
    "# --------------------------------------------\n",
    "# logger\n",
    "# --------------------------------------------\n",
    "'''\n",
    "\n",
    "\n",
    "def logger_info(logger_name, log_path='default_logger.log', mode='a'):\n",
    "    ''' set up logger\n",
    "    modified by Kai Zhang (github: https://github.com/cszn)\n",
    "    '''\n",
    "    log = logging.getLogger(logger_name)\n",
    "    if log.hasHandlers():\n",
    "        print('LogHandlers exist!')\n",
    "    else:\n",
    "        print('LogHandlers setup!')\n",
    "        level = logging.INFO\n",
    "        formatter = logging.Formatter('%(asctime)s.%(msecs)03d : %(message)s', datefmt='%y-%m-%d %H:%M:%S')\n",
    "        fh = logging.FileHandler(log_path, mode=mode)\n",
    "        fh.setFormatter(formatter)\n",
    "        log.setLevel(level)\n",
    "        log.addHandler(fh)\n",
    "        # print(len(log.handlers))\n",
    "\n",
    "        sh = logging.StreamHandler()\n",
    "        sh.setFormatter(formatter)\n",
    "        log.addHandler(sh)\n",
    "\n",
    "\n",
    "'''\n",
    "# --------------------------------------------\n",
    "# print to file and std_out simultaneously\n",
    "# --------------------------------------------\n",
    "'''\n",
    "\n",
    "\n",
    "class logger_print(object):\n",
    "    def __init__(self, log_path=\"default.log\"):\n",
    "        self.terminal = sys.stdout\n",
    "        self.log = open(log_path, 'a')\n",
    "\n",
    "    def write(self, message):\n",
    "        self.terminal.write(message)\n",
    "        self.log.write(message)  # write the message\n",
    "\n",
    "    def flush(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### util_calculate_psnr_ssim.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def calculate_psnr(img1, img2, crop_border, input_order='HWC', test_y_channel=False):\n",
    "    \"\"\"Calculate PSNR (Peak Signal-to-Noise Ratio).\n",
    "\n",
    "    Ref: https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio\n",
    "\n",
    "    Args:\n",
    "        img1 (ndarray): Images with range [0, 255].\n",
    "        img2 (ndarray): Images with range [0, 255].\n",
    "        crop_border (int): Cropped pixels in each edge of an image. These\n",
    "            pixels are not involved in the PSNR calculation.\n",
    "        input_order (str): Whether the input order is 'HWC' or 'CHW'.\n",
    "            Default: 'HWC'.\n",
    "        test_y_channel (bool): Test on Y channel of YCbCr. Default: False.\n",
    "\n",
    "    Returns:\n",
    "        float: psnr result.\n",
    "    \"\"\"\n",
    "\n",
    "    assert img1.shape == img2.shape, (f'Image shapes are differnet: {img1.shape}, {img2.shape}.')\n",
    "    if input_order not in ['HWC', 'CHW']:\n",
    "        raise ValueError(f'Wrong input_order {input_order}. Supported input_orders are ' '\"HWC\" and \"CHW\"')\n",
    "    img1 = reorder_image(img1, input_order=input_order)\n",
    "    img2 = reorder_image(img2, input_order=input_order)\n",
    "    img1 = img1.astype(np.float64)\n",
    "    img2 = img2.astype(np.float64)\n",
    "\n",
    "    if crop_border != 0:\n",
    "        img1 = img1[crop_border:-crop_border, crop_border:-crop_border, ...]\n",
    "        img2 = img2[crop_border:-crop_border, crop_border:-crop_border, ...]\n",
    "\n",
    "    if test_y_channel:\n",
    "        img1 = to_y_channel(img1)\n",
    "        img2 = to_y_channel(img2)\n",
    "\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20. * np.log10(255. / np.sqrt(mse))\n",
    "\n",
    "\n",
    "def _ssim(img1, img2):\n",
    "    \"\"\"Calculate SSIM (structural similarity) for one channel images.\n",
    "\n",
    "    It is called by func:`calculate_ssim`.\n",
    "\n",
    "    Args:\n",
    "        img1 (ndarray): Images with range [0, 255] with order 'HWC'.\n",
    "        img2 (ndarray): Images with range [0, 255] with order 'HWC'.\n",
    "\n",
    "    Returns:\n",
    "        float: ssim result.\n",
    "    \"\"\"\n",
    "\n",
    "    C1 = (0.01 * 255) ** 2\n",
    "    C2 = (0.03 * 255) ** 2\n",
    "\n",
    "    img1 = img1.astype(np.float64)\n",
    "    img2 = img2.astype(np.float64)\n",
    "    kernel = cv2.getGaussianKernel(11, 1.5)\n",
    "    window = np.outer(kernel, kernel.transpose())\n",
    "\n",
    "    mu1 = cv2.filter2D(img1, -1, window)[5:-5, 5:-5]\n",
    "    mu2 = cv2.filter2D(img2, -1, window)[5:-5, 5:-5]\n",
    "    mu1_sq = mu1 ** 2\n",
    "    mu2_sq = mu2 ** 2\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "    sigma1_sq = cv2.filter2D(img1 ** 2, -1, window)[5:-5, 5:-5] - mu1_sq\n",
    "    sigma2_sq = cv2.filter2D(img2 ** 2, -1, window)[5:-5, 5:-5] - mu2_sq\n",
    "    sigma12 = cv2.filter2D(img1 * img2, -1, window)[5:-5, 5:-5] - mu1_mu2\n",
    "\n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "    return ssim_map.mean()\n",
    "\n",
    "\n",
    "def calculate_ssim(img1, img2, crop_border, input_order='HWC', test_y_channel=False):\n",
    "    \"\"\"Calculate SSIM (structural similarity).\n",
    "\n",
    "    Ref:\n",
    "    Image quality assessment: From error visibility to structural similarity\n",
    "\n",
    "    The results are the same as that of the official released MATLAB code in\n",
    "    https://ece.uwaterloo.ca/~z70wang/research/ssim/.\n",
    "\n",
    "    For three-channel images, SSIM is calculated for each channel and then\n",
    "    averaged.\n",
    "\n",
    "    Args:\n",
    "        img1 (ndarray): Images with range [0, 255].\n",
    "        img2 (ndarray): Images with range [0, 255].\n",
    "        crop_border (int): Cropped pixels in each edge of an image. These\n",
    "            pixels are not involved in the SSIM calculation.\n",
    "        input_order (str): Whether the input order is 'HWC' or 'CHW'.\n",
    "            Default: 'HWC'.\n",
    "        test_y_channel (bool): Test on Y channel of YCbCr. Default: False.\n",
    "\n",
    "    Returns:\n",
    "        float: ssim result.\n",
    "    \"\"\"\n",
    "\n",
    "    assert img1.shape == img2.shape, (f'Image shapes are differnet: {img1.shape}, {img2.shape}.')\n",
    "    if input_order not in ['HWC', 'CHW']:\n",
    "        raise ValueError(f'Wrong input_order {input_order}. Supported input_orders are ' '\"HWC\" and \"CHW\"')\n",
    "    img1 = reorder_image(img1, input_order=input_order)\n",
    "    img2 = reorder_image(img2, input_order=input_order)\n",
    "    img1 = img1.astype(np.float64)\n",
    "    img2 = img2.astype(np.float64)\n",
    "\n",
    "    if crop_border != 0:\n",
    "        img1 = img1[crop_border:-crop_border, crop_border:-crop_border, ...]\n",
    "        img2 = img2[crop_border:-crop_border, crop_border:-crop_border, ...]\n",
    "\n",
    "    if test_y_channel:\n",
    "        img1 = to_y_channel(img1)\n",
    "        img2 = to_y_channel(img2)\n",
    "\n",
    "    ssims = []\n",
    "    for i in range(img1.shape[2]):\n",
    "        ssims.append(_ssim(img1[..., i], img2[..., i]))\n",
    "    return np.array(ssims).mean()\n",
    "\n",
    "\n",
    "def _blocking_effect_factor(im):\n",
    "    block_size = 8\n",
    "\n",
    "    block_horizontal_positions = torch.arange(7, im.shape[3] - 1, 8)\n",
    "    block_vertical_positions = torch.arange(7, im.shape[2] - 1, 8)\n",
    "\n",
    "    horizontal_block_difference = (\n",
    "                (im[:, :, :, block_horizontal_positions] - im[:, :, :, block_horizontal_positions + 1]) ** 2).sum(\n",
    "        3).sum(2).sum(1)\n",
    "    vertical_block_difference = (\n",
    "                (im[:, :, block_vertical_positions, :] - im[:, :, block_vertical_positions + 1, :]) ** 2).sum(3).sum(\n",
    "        2).sum(1)\n",
    "\n",
    "    nonblock_horizontal_positions = np.setdiff1d(torch.arange(0, im.shape[3] - 1), block_horizontal_positions)\n",
    "    nonblock_vertical_positions = np.setdiff1d(torch.arange(0, im.shape[2] - 1), block_vertical_positions)\n",
    "\n",
    "    horizontal_nonblock_difference = (\n",
    "                (im[:, :, :, nonblock_horizontal_positions] - im[:, :, :, nonblock_horizontal_positions + 1]) ** 2).sum(\n",
    "        3).sum(2).sum(1)\n",
    "    vertical_nonblock_difference = (\n",
    "                (im[:, :, nonblock_vertical_positions, :] - im[:, :, nonblock_vertical_positions + 1, :]) ** 2).sum(\n",
    "        3).sum(2).sum(1)\n",
    "\n",
    "    n_boundary_horiz = im.shape[2] * (im.shape[3] // block_size - 1)\n",
    "    n_boundary_vert = im.shape[3] * (im.shape[2] // block_size - 1)\n",
    "    boundary_difference = (horizontal_block_difference + vertical_block_difference) / (\n",
    "                n_boundary_horiz + n_boundary_vert)\n",
    "\n",
    "    n_nonboundary_horiz = im.shape[2] * (im.shape[3] - 1) - n_boundary_horiz\n",
    "    n_nonboundary_vert = im.shape[3] * (im.shape[2] - 1) - n_boundary_vert\n",
    "    nonboundary_difference = (horizontal_nonblock_difference + vertical_nonblock_difference) / (\n",
    "                n_nonboundary_horiz + n_nonboundary_vert)\n",
    "\n",
    "    scaler = np.log2(block_size) / np.log2(min([im.shape[2], im.shape[3]]))\n",
    "    bef = scaler * (boundary_difference - nonboundary_difference)\n",
    "\n",
    "    bef[boundary_difference <= nonboundary_difference] = 0\n",
    "    return bef\n",
    "\n",
    "\n",
    "def calculate_psnrb(img1, img2, crop_border, input_order='HWC', test_y_channel=False):\n",
    "    \"\"\"Calculate PSNR-B (Peak Signal-to-Noise Ratio).\n",
    "\n",
    "    Ref: Quality assessment of deblocked images, for JPEG image deblocking evaluation\n",
    "    # https://gitlab.com/Queuecumber/quantization-guided-ac/-/blob/master/metrics/psnrb.py\n",
    "\n",
    "    Args:\n",
    "        img1 (ndarray): Images with range [0, 255].\n",
    "        img2 (ndarray): Images with range [0, 255].\n",
    "        crop_border (int): Cropped pixels in each edge of an image. These\n",
    "            pixels are not involved in the PSNR calculation.\n",
    "        input_order (str): Whether the input order is 'HWC' or 'CHW'.\n",
    "            Default: 'HWC'.\n",
    "        test_y_channel (bool): Test on Y channel of YCbCr. Default: False.\n",
    "\n",
    "    Returns:\n",
    "        float: psnr result.\n",
    "    \"\"\"\n",
    "\n",
    "    assert img1.shape == img2.shape, (f'Image shapes are differnet: {img1.shape}, {img2.shape}.')\n",
    "    if input_order not in ['HWC', 'CHW']:\n",
    "        raise ValueError(f'Wrong input_order {input_order}. Supported input_orders are ' '\"HWC\" and \"CHW\"')\n",
    "    img1 = reorder_image(img1, input_order=input_order)\n",
    "    img2 = reorder_image(img2, input_order=input_order)\n",
    "    img1 = img1.astype(np.float64)\n",
    "    img2 = img2.astype(np.float64)\n",
    "\n",
    "    if crop_border != 0:\n",
    "        img1 = img1[crop_border:-crop_border, crop_border:-crop_border, ...]\n",
    "        img2 = img2[crop_border:-crop_border, crop_border:-crop_border, ...]\n",
    "\n",
    "    if test_y_channel:\n",
    "        img1 = to_y_channel(img1)\n",
    "        img2 = to_y_channel(img2)\n",
    "\n",
    "    # follow https://gitlab.com/Queuecumber/quantization-guided-ac/-/blob/master/metrics/psnrb.py\n",
    "    img1 = torch.from_numpy(img1).permute(2, 0, 1).unsqueeze(0) / 255.\n",
    "    img2 = torch.from_numpy(img2).permute(2, 0, 1).unsqueeze(0) / 255.\n",
    "\n",
    "    total = 0\n",
    "    for c in range(img1.shape[1]):\n",
    "        mse = torch.nn.functional.mse_loss(img1[:, c:c + 1, :, :], img2[:, c:c + 1, :, :], reduction='none')\n",
    "        bef = _blocking_effect_factor(img1[:, c:c + 1, :, :])\n",
    "\n",
    "        mse = mse.view(mse.shape[0], -1).mean(1)\n",
    "        total += 10 * torch.log10(1 / (mse + bef))\n",
    "\n",
    "    return float(total) / img1.shape[1]\n",
    "\n",
    "\n",
    "def reorder_image(img, input_order='HWC'):\n",
    "    \"\"\"Reorder images to 'HWC' order.\n",
    "\n",
    "    If the input_order is (h, w), return (h, w, 1);\n",
    "    If the input_order is (c, h, w), return (h, w, c);\n",
    "    If the input_order is (h, w, c), return as it is.\n",
    "\n",
    "    Args:\n",
    "        img (ndarray): Input image.\n",
    "        input_order (str): Whether the input order is 'HWC' or 'CHW'.\n",
    "            If the input image shape is (h, w), input_order will not have\n",
    "            effects. Default: 'HWC'.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: reordered image.\n",
    "    \"\"\"\n",
    "\n",
    "    if input_order not in ['HWC', 'CHW']:\n",
    "        raise ValueError(f'Wrong input_order {input_order}. Supported input_orders are ' \"'HWC' and 'CHW'\")\n",
    "    if len(img.shape) == 2:\n",
    "        img = img[..., None]\n",
    "    if input_order == 'CHW':\n",
    "        img = img.transpose(1, 2, 0)\n",
    "    return img\n",
    "\n",
    "\n",
    "def to_y_channel(img):\n",
    "    \"\"\"Change to Y channel of YCbCr.\n",
    "\n",
    "    Args:\n",
    "        img (ndarray): Images with range [0, 255].\n",
    "\n",
    "    Returns:\n",
    "        (ndarray): Images with range [0, 255] (float type) without round.\n",
    "    \"\"\"\n",
    "    img = img.astype(np.float32) / 255.\n",
    "    if img.ndim == 3 and img.shape[2] == 3:\n",
    "        img = bgr2ycbcr(img, y_only=True)\n",
    "        img = img[..., None]\n",
    "    return img * 255.\n",
    "\n",
    "\n",
    "def _convert_input_type_range(img):\n",
    "    \"\"\"Convert the type and range of the input image.\n",
    "\n",
    "    It converts the input image to np.float32 type and range of [0, 1].\n",
    "    It is mainly used for pre-processing the input image in colorspace\n",
    "    convertion functions such as rgb2ycbcr and ycbcr2rgb.\n",
    "\n",
    "    Args:\n",
    "        img (ndarray): The input image. It accepts:\n",
    "            1. np.uint8 type with range [0, 255];\n",
    "            2. np.float32 type with range [0, 1].\n",
    "\n",
    "    Returns:\n",
    "        (ndarray): The converted image with type of np.float32 and range of\n",
    "            [0, 1].\n",
    "    \"\"\"\n",
    "    img_type = img.dtype\n",
    "    img = img.astype(np.float32)\n",
    "    if img_type == np.float32:\n",
    "        pass\n",
    "    elif img_type == np.uint8:\n",
    "        img /= 255.\n",
    "    else:\n",
    "        raise TypeError('The img type should be np.float32 or np.uint8, ' f'but got {img_type}')\n",
    "    return img\n",
    "\n",
    "\n",
    "def _convert_output_type_range(img, dst_type):\n",
    "    \"\"\"Convert the type and range of the image according to dst_type.\n",
    "\n",
    "    It converts the image to desired type and range. If `dst_type` is np.uint8,\n",
    "    images will be converted to np.uint8 type with range [0, 255]. If\n",
    "    `dst_type` is np.float32, it converts the image to np.float32 type with\n",
    "    range [0, 1].\n",
    "    It is mainly used for post-processing images in colorspace convertion\n",
    "    functions such as rgb2ycbcr and ycbcr2rgb.\n",
    "\n",
    "    Args:\n",
    "        img (ndarray): The image to be converted with np.float32 type and\n",
    "            range [0, 255].\n",
    "        dst_type (np.uint8 | np.float32): If dst_type is np.uint8, it\n",
    "            converts the image to np.uint8 type with range [0, 255]. If\n",
    "            dst_type is np.float32, it converts the image to np.float32 type\n",
    "            with range [0, 1].\n",
    "\n",
    "    Returns:\n",
    "        (ndarray): The converted image with desired type and range.\n",
    "    \"\"\"\n",
    "    if dst_type not in (np.uint8, np.float32):\n",
    "        raise TypeError('The dst_type should be np.float32 or np.uint8, ' f'but got {dst_type}')\n",
    "    if dst_type == np.uint8:\n",
    "        img = img.round()\n",
    "    else:\n",
    "        img /= 255.\n",
    "    return img.astype(dst_type)\n",
    "\n",
    "\n",
    "def bgr2ycbcr(img, y_only=False):\n",
    "    \"\"\"Convert a BGR image to YCbCr image.\n",
    "\n",
    "    The bgr version of rgb2ycbcr.\n",
    "    It implements the ITU-R BT.601 conversion for standard-definition\n",
    "    television. See more details in\n",
    "    https://en.wikipedia.org/wiki/YCbCr#ITU-R_BT.601_conversion.\n",
    "\n",
    "    It differs from a similar function in cv2.cvtColor: `BGR <-> YCrCb`.\n",
    "    In OpenCV, it implements a JPEG conversion. See more details in\n",
    "    https://en.wikipedia.org/wiki/YCbCr#JPEG_conversion.\n",
    "\n",
    "    Args:\n",
    "        img (ndarray): The input image. It accepts:\n",
    "            1. np.uint8 type with range [0, 255];\n",
    "            2. np.float32 type with range [0, 1].\n",
    "        y_only (bool): Whether to only return Y channel. Default: False.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: The converted YCbCr image. The output image has the same type\n",
    "            and range as input image.\n",
    "    \"\"\"\n",
    "    img_type = img.dtype\n",
    "    img = _convert_input_type_range(img)\n",
    "    if y_only:\n",
    "        out_img = np.dot(img, [24.966, 128.553, 65.481]) + 16.0\n",
    "    else:\n",
    "        out_img = np.matmul(\n",
    "            img, [[24.966, 112.0, -18.214], [128.553, -74.203, -93.786], [65.481, -37.797, 112.0]]) + [16, 128, 128]\n",
    "    out_img = _convert_output_type_range(out_img, img_type)\n",
    "    return out_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RRDB.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def make_layer(block, n_layers):\n",
    "    layers = []\n",
    "    for _ in range(n_layers):\n",
    "        layers.append(block())\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class ResidualDenseBlock_5C(nn.Module):\n",
    "    def __init__(self, nf=64, gc=32, bias=True):\n",
    "        super(ResidualDenseBlock_5C, self).__init__()\n",
    "        # gc: growth channel, i.e. intermediate channels\n",
    "        self.conv1 = nn.Conv2d(nf, gc, 3, 1, 1, bias=bias)\n",
    "        self.conv2 = nn.Conv2d(nf + gc, gc, 3, 1, 1, bias=bias)\n",
    "        self.conv3 = nn.Conv2d(nf + 2 * gc, gc, 3, 1, 1, bias=bias)\n",
    "        self.conv4 = nn.Conv2d(nf + 3 * gc, gc, 3, 1, 1, bias=bias)\n",
    "        self.conv5 = nn.Conv2d(nf + 4 * gc, nf, 3, 1, 1, bias=bias)\n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"Init weights for ResidualDenseBlock.\n",
    "\n",
    "        Use smaller std for better stability and performance. We empirically\n",
    "        use 0.1. See more details in \"ESRGAN: Enhanced Super-Resolution\n",
    "        Generative Adversarial Networks\"\n",
    "        \"\"\"\n",
    "        for i in range(5):\n",
    "            default_init_weights(getattr(self, f'conv{i+1}'), 0.1)\n",
    "\n",
    "        # initialization\n",
    "        # mutil.initialize_weights([self.conv1, self.conv2, self.conv3, self.conv4, self.conv5], 0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.lrelu(self.conv1(x))\n",
    "        x2 = self.lrelu(self.conv2(torch.cat((x, x1), 1)))\n",
    "        x3 = self.lrelu(self.conv3(torch.cat((x, x1, x2), 1)))\n",
    "        x4 = self.lrelu(self.conv4(torch.cat((x, x1, x2, x3), 1)))\n",
    "        x5 = self.conv5(torch.cat((x, x1, x2, x3, x4), 1))\n",
    "        return x5 * 0.2 + x\n",
    "\n",
    "\n",
    "def default_init_weights(module, scale=1):\n",
    "    \"\"\"Initialize network weights.\n",
    "\n",
    "    Args:\n",
    "        modules (nn.Module): Modules to be initialized.\n",
    "        scale (float): Scale initialized weights, especially for residual\n",
    "            blocks.\n",
    "    \"\"\"\n",
    "    for m in module.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(m.weight, a=0, mode='fan_in', nonlinearity='relu')\n",
    "            m.weight.data *= scale\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight, a=0, mode='fan_in', nonlinearity='relu')\n",
    "            m.weight.data *= scale\n",
    "\n",
    "\n",
    "class RRDB(nn.Module):\n",
    "    '''Residual in Residual Dense Block'''\n",
    "\n",
    "    def __init__(self, nf=64, gc=32):\n",
    "        super(RRDB, self).__init__()\n",
    "        self.RDB1 = ResidualDenseBlock_5C(nf, gc)\n",
    "        self.RDB2 = ResidualDenseBlock_5C(nf, gc)\n",
    "        self.RDB3 = ResidualDenseBlock_5C(nf, gc)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.RDB1(x)\n",
    "        out = self.RDB2(out)\n",
    "        out = self.RDB3(out)\n",
    "        return out * 0.2 + x\n",
    "\n",
    "\n",
    "class RRDBNet(nn.Module):\n",
    "    def __init__(self, in_nc, out_nc, nf=64, nb=23, gc=32):\n",
    "        super(RRDBNet, self).__init__()\n",
    "        RRDB_block_f = functools.partial(RRDB, nf=nf, gc=gc)\n",
    "\n",
    "        self.conv_first = nn.Conv2d(in_nc, nf, 3, 1, 1, bias=True)\n",
    "        self.RRDB_trunk = make_layer(RRDB_block_f, nb)\n",
    "        self.trunk_conv = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
    "        #### upsampling\n",
    "        # self.upconv1 = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
    "        # self.upconv2 = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
    "        self.HRconv = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
    "        self.conv_last = nn.Conv2d(nf, out_nc, 3, 1, 1, bias=True)\n",
    "\n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        fea = self.conv_first(x)\n",
    "        trunk = self.trunk_conv(self.RRDB_trunk(fea))\n",
    "        fea = fea + trunk\n",
    "\n",
    "        # fea = self.lrelu(self.upconv1(F.interpolate(fea, scale_factor=2, mode='nearest')))\n",
    "        # fea = self.lrelu(self.upconv2(F.interpolate(fea, scale_factor=2, mode='nearest')))\n",
    "        out = self.conv_last(self.lrelu(self.HRconv(fea)))\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class RRDBNetX4(nn.Module):\n",
    "    def __init__(self, in_nc, out_nc, nf=64, nb=23, gc=32):\n",
    "        super(RRDBNetX4, self).__init__()\n",
    "        RRDB_block_f = functools.partial(RRDB, nf=nf, gc=gc)\n",
    "\n",
    "        self.conv_first = nn.Conv2d(in_nc, nf, 3, 1, 1, bias=True)\n",
    "        self.RRDB_trunk = make_layer(RRDB_block_f, nb)\n",
    "        self.trunk_conv = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
    "        #### upsampling\n",
    "        self.upconv1 = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
    "        self.upconv2 = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
    "        self.HRconv = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
    "        self.conv_last = nn.Conv2d(nf, out_nc, 3, 1, 1, bias=True)\n",
    "\n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        fea = self.conv_first(x)\n",
    "        trunk = self.trunk_conv(self.RRDB_trunk(fea))\n",
    "        fea = fea + trunk\n",
    "\n",
    "        fea = self.lrelu(self.upconv1(F.interpolate(fea, scale_factor=2, mode='nearest')))\n",
    "        fea = self.lrelu(self.upconv2(F.interpolate(fea, scale_factor=2, mode='nearest')))\n",
    "        out = self.conv_last(self.lrelu(self.HRconv(fea)))\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIL_sf_noise.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.utils import data\n",
    "from torch import distributed as dist\n",
    "import torch.optim as optim\n",
    "import srdata_noise\n",
    "import utils_logger\n",
    "import logging\n",
    "import util_calculate_psnr_ssim as util\n",
    "\n",
    "from RRDB import RRDBNet\n",
    "\n",
    "\n",
    "def synchronize():\n",
    "    if not dist.is_available():\n",
    "        return\n",
    "\n",
    "    if not dist.is_initialized():\n",
    "        return\n",
    "\n",
    "    world_size = dist.get_world_size()\n",
    "\n",
    "    if world_size == 1:\n",
    "        return\n",
    "\n",
    "    dist.barrier()\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Train an editor')\n",
    "\n",
    "    parser.add_argument('--gpus', type=int, default=1, help='number of gpus to use')\n",
    "    parser.add_argument('--seed', type=int, default=1, help='random seed')\n",
    "    parser.add_argument(\n",
    "        \"--ckpt_save\",\n",
    "        type=str,\n",
    "        default=None,\n",
    "        help=\"path to save checkpoints\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--resume\",\n",
    "        type=str,\n",
    "        default=None,\n",
    "        help=\"path to checkpoints for pretrained model\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--distributed',\n",
    "        action='store_true'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--local_rank\", type=int, default=0, help=\"local rank for distributed training\"\n",
    "    )\n",
    "    parser.add_argument('--trainset', type=str, help='path to the train set')\n",
    "    parser.add_argument('--patch_size', type=int, default=64)\n",
    "    parser.add_argument('--testset', type=str, default='default', help='path to the test set, default is Set5')\n",
    "\n",
    "    parser.add_argument('--save_every', type=int, default=1, help='save weights')\n",
    "    parser.add_argument('--test_every', type=int, default=5, help='save weights')\n",
    "    parser.add_argument('--print_every', type=int, default=100)\n",
    "    parser.add_argument('--batch_size', type=int, default=32, help='input batch size for training')\n",
    "    parser.add_argument('--num_workder', type=int, default=8)\n",
    "    parser.add_argument('--total_epoch', type=int, default=30)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args\n",
    "\n",
    "def data_sampler(dataset, shuffle=True, distributed=True):\n",
    "    if distributed:\n",
    "        return data.distributed.DistributedSampler(dataset, shuffle=shuffle)\n",
    "\n",
    "    if shuffle:\n",
    "        return data.RandomSampler(dataset)\n",
    "\n",
    "    else:\n",
    "        return data.SequentialSampler(dataset)\n",
    "\n",
    "def point_grad_to(meta_net, task_net):\n",
    "    '''\n",
    "    Set .grad attribute of each parameter to be proportional\n",
    "    to the difference between self and target\n",
    "    '''\n",
    "    for meta_p, task_p in zip(meta_net.parameters(), task_net.parameters()):\n",
    "        if meta_p.grad is None:\n",
    "            meta_p.grad = torch.zeros(meta_p.size()).cuda()\n",
    "        # meta_p.grad.data.zero_()  # not required as optimizer.zero_grad\n",
    "        meta_p.grad.data.add_(meta_p.data - task_p.data)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    args = parse_args()\n",
    "\n",
    "    ## initialize training folder\n",
    "    checkpoint_save_path = args.ckpt_save\n",
    "    if not os.path.exists(checkpoint_save_path):\n",
    "        os.makedirs(checkpoint_save_path, exist_ok=True)\n",
    "\n",
    "    logger_name = 'train'\n",
    "    utils_logger.logger_info(logger_name, os.path.join(checkpoint_save_path, logger_name+'.log'))\n",
    "    logger = logging.getLogger(logger_name)\n",
    "\n",
    "    ## initialize DDP training\n",
    "    if args.distributed:\n",
    "        torch.cuda.set_deviRRce(args.local_rank)\n",
    "        torch.distributed.init_process_group(backend=\"nccl\")\n",
    "    \n",
    "    if args.seed is not None:\n",
    "        logger.info('Set random seed to {}'.format(args.seed))\n",
    "        torch.manual_seed(args.seed)\n",
    "        torch.cuda.manual_seed(args.seed)\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "    ## initialize model and optimizer\n",
    "    model_task = RRDBNet(in_nc=3, out_nc=3).to('cuda')\n",
    "    model_meta = RRDBNet(in_nc=3, out_nc=3).to('cuda')\n",
    "\n",
    "    optimizer_task = optim.Adam([p for p in model_task.parameters() if p.requires_grad], lr=1.e-4, betas=(0, 0.999))\n",
    "    optimizer_meta = optim.Adam([p for p in model_meta.parameters() if p.requires_grad], lr=1.e-4)\n",
    "\n",
    "    if args.resume is not None:\n",
    "        print(\"load model: \", args.resume)\n",
    "        ckpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
    "        model_task.load_state_dict(ckpt['model_task'])\n",
    "        model_meta.load_state_dict(ckpt['model_meta'])\n",
    "\n",
    "    \n",
    "    loss_fn = torch.nn.L1Loss()\n",
    "    loss_fn = loss_fn.to('cuda')\n",
    "\n",
    "    ## for gaussian denoising, we set task number to 4\n",
    "    dataset_list = []\n",
    "    for i in range(4):\n",
    "        dataset_list.append(srdata_noise.DataCrop(i, hr_folder=args.trainset, patch_size=args.patch_size))\n",
    "\n",
    "    testset = srdata_noise.DataTest(hr_folder=args.testset, level=50)  # you can try 50, 70 ...\n",
    "\n",
    "    dataloader_test = data.DataLoader(\n",
    "        testset, \n",
    "        batch_size=1,\n",
    "        sampler=data_sampler(testset, shuffle=False, distributed=False),\n",
    "        num_workers=1,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    dataloader_list = [\n",
    "        data.DataLoader(\n",
    "        trainset, \n",
    "        batch_size=args.batch_size,\n",
    "        sampler=data_sampler(trainset, shuffle=True, distributed=args.distributed),\n",
    "        num_workers=args.num_workder,\n",
    "        pin_memory=True,\n",
    "        drop_last=True\n",
    "        )\n",
    "        for trainset in dataset_list\n",
    "    ]\n",
    "\n",
    "\n",
    "    if args.distributed:\n",
    "        model_task = DistributedDataParallel(\n",
    "            model_task,\n",
    "            device_ids=[args.local_rank],\n",
    "            output_device=args.local_rank,\n",
    "            broadcast_buffers=True,\n",
    "        )\n",
    "        model_meta = DistributedDataParallel(\n",
    "            model_meta,\n",
    "            device_ids=[args.local_rank],\n",
    "            output_device=args.local_rank,\n",
    "            broadcast_buffers=True,\n",
    "        )\n",
    "\n",
    "\n",
    "    total_epochs = args.total_epoch\n",
    "    state_task = None\n",
    "\n",
    "    for epoch in range(total_epochs):\n",
    "\n",
    "        if epoch and not (epoch % 20):\n",
    "            for param in optimizer_meta.param_groups:\n",
    "                param['lr'] = (param['lr'] * 0.5) if param['lr'] > 1.e-6 else 1.e-6\n",
    "            sche = True\n",
    "\n",
    "        learning_rate_f = optimizer_task.param_groups[0]['lr']\n",
    "        learning_rate_s = optimizer_meta.param_groups[0]['lr']\n",
    "\n",
    "        data_len = len(dataset_list[0])\n",
    "\n",
    "        data_loader_train = [iter(dataloader) for dataloader in dataloader_list]\n",
    "\n",
    "        random_list = [0, 1, 2, 3]\n",
    "        np.random.seed(1)  # to control random_list is same on every gpus.\n",
    "\n",
    "        for iteration in range(data_len // (args.batch_size * args.gpus)):\n",
    "            model_task.load_state_dict(model_meta.state_dict())\n",
    "\n",
    "            if state_task is not None:\n",
    "                optimizer_task.load_state_dict(state_task)\n",
    "\n",
    "            np.random.shuffle(random_list)\n",
    "\n",
    "            for ind in random_list:\n",
    "                dl = data_loader_train[ind]\n",
    "\n",
    "                lr, hr = dl.next()\n",
    "                    \n",
    "                optimizer_task.zero_grad()\n",
    "                lr = lr.to('cuda')\n",
    "                hr = hr.to('cuda')\n",
    "                sr = model_task(lr)\n",
    "                loss = loss_fn(sr, hr)\n",
    "                loss_print = loss.item()\n",
    "                loss.backward()\n",
    "                optimizer_task.step()\n",
    "\n",
    "                if torch.cuda.current_device() == 0 and not iteration % args.print_every:\n",
    "                    logger.info('Epoch: {}\\tIter: {}/{}\\tTask loss: {}\\tTask LR: {:.6f}\\tMeta LR: {:.6f}'.format(epoch, iteration, data_len // (args.batch_size * args.gpus), loss_print, learning_rate_f, learning_rate_s))\n",
    "\n",
    "            state_task = optimizer_task.state_dict()\n",
    "            optimizer_meta.zero_grad()\n",
    "            point_grad_to(model_meta, model_task)\n",
    "            optimizer_meta.step()\n",
    "            \n",
    "            if torch.cuda.current_device() == 0 and not iteration % args.print_every:\n",
    "                logger.info('Meta net updated!')\n",
    "\n",
    "        # save model\n",
    "        if not epoch % args.save_every and torch.cuda.current_device() == 0:\n",
    "            m_task = model_task.module if args.distributed else model_task\n",
    "            m_meta = model_meta.module if args.distributed else model_meta\n",
    "            model_meta_dict = m_meta.state_dict()\n",
    "            model_task_dict = m_task.state_dict()\n",
    "            torch.save(\n",
    "                {\n",
    "                    'model_meta': model_meta_dict,\n",
    "                    'model_task': model_task_dict,\n",
    "                },\n",
    "                os.path.join(checkpoint_save_path, 'model_{}.pt'.format(epoch+1))\n",
    "            )\n",
    "        # test model\n",
    "        if not epoch % args.test_every and torch.cuda.current_device() == 0:\n",
    "                model_meta.eval()\n",
    "                p = 0\n",
    "                s = 0\n",
    "                count = 0\n",
    "                \n",
    "                for lr, hr, filename in dataloader_test:\n",
    "                    count += 1\n",
    "                    lr = lr.to('cuda')\n",
    "                    filename = filename[0]\n",
    "                    with torch.no_grad():\n",
    "                        sr = model_meta(lr)\n",
    "                    sr = sr.detach().cpu().squeeze(0).numpy().transpose(1, 2, 0)\n",
    "                    sr = sr * 255.\n",
    "                    sr = np.clip(sr.round(), 0, 255).astype(np.uint8)\n",
    "                    hr = hr.squeeze(0).numpy().transpose(1, 2, 0)\n",
    "                    hr = hr * 255.\n",
    "                    hr = np.clip(hr.round(), 0, 255).astype(np.uint8)\n",
    "\n",
    "                    sr = cv2.cvtColor(sr, cv2.COLOR_RGB2BGR)\n",
    "                    hr = cv2.cvtColor(hr, cv2.COLOR_RGB2BGR)\n",
    "                    psnr = util.calculate_psnr(sr, hr, crop_border=0)\n",
    "                    ssim = util.calculate_ssim(sr, hr, crop_border=0)\n",
    "                    p += psnr\n",
    "                    s += ssim\n",
    "                    logger.info('{}: {}, {}'.format(filename, psnr, ssim))\n",
    "\n",
    "                p /= count\n",
    "                s /= count\n",
    "                logger.info(\"Epoch: {}, psnr: {}. ssim: {}.\".format(epoch, p, s))\n",
    "                \n",
    "                model_meta.train()\n",
    "    \n",
    "    \n",
    "    logger.info('Done')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xây dựng mô hình sử dụng $\\text{DIR}_{\\text{sf}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huấn luyện\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Đánh giá"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uit-cs431",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
